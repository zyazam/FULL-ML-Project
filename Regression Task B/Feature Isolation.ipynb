{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7487,
          "sourceType": "datasetVersion",
          "datasetId": 4931
        }
      ],
      "dockerImageVersionId": 31236,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Regression Task: Target Selection\n",
        "\n",
        "Target Variable: 'days_since_prior_order'\n",
        "\n",
        "\"We chose to predict the time interval between orders rather than reorder counts for its high strategic value. Predicting when a customer will return allows for:\n",
        "\n",
        "Precision Retargeting: Sending marketing incentives at the exact moment a customer is likely to restock.\n",
        "\n",
        "Dynamic Scheduling: Optimizing logistics and supply chain operations based on predicted temporal demand.\n",
        "\n",
        "Customer Churn Prevention: Identifying deviations from predicted ordering cycles to intervene before a customer stops using the platform.\""
      ],
      "metadata": {
        "id": "E6GMqUtrp6cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Isolation:\n",
        "To ensure a robust regression model for predicting days_since_prior_order, the following technical steps were implemented:\n",
        "\n",
        "Feature Isolation: I isolated behavioral features by explicitly removing identifiers (user_id, product_id) and the classification target. This prevents Data Leakage and ensures the model learns only from relevant user behavior.\n",
        "\n",
        "Categorical Integrity: Handled categorical variables by converting them to string formats. This was a critical step to prevent TypeErrors during the imputation phase, especially when dealing with high-cardinality features.\n",
        "\n",
        "Memory-Efficient Imputation: Applied a zero-filling strategy (fillna(0)) across the feature set and the target variable. This approach was chosen to maintain a dense matrix structure while keeping the memory footprint low for the 10-million-row dataset.\n",
        "\n",
        "Deterministic Splitting: Utilized an 80/20 train-test split with a fixed random_state to ensure the reproducibility of results during model evaluation."
      ],
      "metadata": {
        "id": "340Ok1JLp6cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Feature Selection & Data Cleaning ---\n",
        "# Removing identifiers and the classification target to isolate features for regression.\n",
        "features = [col for col in My_Data_Aggregated.columns if col not in ['user_id', 'product_id', 'target', 'days_since_prior_order']]\n",
        "\n",
        "X = My_Data_Aggregated[features].copy()\n",
        "\n",
        "# Handling Categorical columns to prevent \"TypeError\" during fillna(0).\n",
        "# We convert categories to strings so that they can accept the new '0' value for missing data.\n",
        "for col in X.select_dtypes(include=['category']).columns:\n",
        "    X[col] = X[col].astype(str)\n",
        "\n",
        "# Filling missing values with 0 for both features and the target variable.\n",
        "X = X.fillna(0)\n",
        "y = My_Data_Aggregated['days_since_prior_order'].fillna(0)\n",
        "\n",
        "# Splitting the dataset into Training (80%) and Testing (20%) sets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-03T16:18:13.134931Z",
          "iopub.execute_input": "2026-01-03T16:18:13.137835Z"
        },
        "id": "0F7efBu0p6cO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# RAM Optimization\n",
        "del X\n",
        "gc.collect()\n",
        "\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Testing set size: {X_test.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2026-01-03T15:54:23.143Z"
        },
        "id": "tdoDgt7qp6cP"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}